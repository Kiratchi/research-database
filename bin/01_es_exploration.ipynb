{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elasticsearch Publications Explorer\n",
    "Step-by-step exploration of Chalmers research publications database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from elasticsearch import Elasticsearch\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from pprint import pprint\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Elasticsearch version: 6.8.23\n",
      "Cluster name: chalmers-elk-test\n"
     ]
    }
   ],
   "source": [
    "# Initialize Elasticsearch client for version 6.x\n",
    "es = Elasticsearch(\n",
    "    hosts=[os.getenv('ES_HOST')],\n",
    "    http_auth=(os.getenv('ES_USER'), os.getenv('ES_PASS')),\n",
    "    verify_certs=True\n",
    ")\n",
    "\n",
    "# Test connection\n",
    "info = es.info()\n",
    "print(f\"Connected to Elasticsearch version: {info['version']['number']}\")\n",
    "print(f\"Cluster name: {info['cluster_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore Index Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: research-publications-static\n",
      "Documents: 713,270\n",
      "Size: 7992.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Get basic info about publications index\n",
    "index_name = \"research-publications-static\"\n",
    "index_stats = es.indices.stats(index=index_name)\n",
    "\n",
    "doc_count = index_stats['indices'][index_name]['total']['docs']['count']\n",
    "size_in_bytes = index_stats['indices'][index_name]['total']['store']['size_in_bytes']\n",
    "size_in_mb = size_in_bytes / (1024 * 1024)\n",
    "\n",
    "print(f\"Index: {index_name}\")\n",
    "print(f\"Documents: {doc_count:,}\")\n",
    "print(f\"Size: {size_in_mb:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level fields in a publication:\n",
      "  Abstract: str\n",
      "  AffiliatedIdsChalmers: list\n",
      "  Categories: list\n",
      "  CreatedBy: str\n",
      "  CreatedDate: str\n",
      "  DataObjects: list\n",
      "  Datasets: list\n",
      "  DetailsUrlEng: str\n",
      "  DetailsUrlSwe: str\n",
      "  HasImportErrors: bool\n",
      "  HasImportMatchOnScopusDoi: bool\n",
      "  HasImportMatchOnScopusId: bool\n",
      "  HasOrganizations: bool\n",
      "  HasPersons: bool\n",
      "  Id: str\n",
      "  IdentifierCplPubid: list\n",
      "  IdentifierDoi: list\n",
      "  IdentifierIsbn: list\n",
      "  IdentifierPubmedId: list\n",
      "  IdentifierScopusId: list\n",
      "  Identifiers: list\n",
      "  IncludedManuscripts: list\n",
      "  IncludedPapers: list\n",
      "  IncludedPapersLegacy: list\n",
      "  IsDeleted: bool\n",
      "  IsDraft: bool\n",
      "  IsImported: bool\n",
      "  Keywords: list\n",
      "  Language: dict\n",
      "  LatestEventDate: str\n",
      "  NeedsAttention: bool\n",
      "  Organizations: list\n",
      "  Persons: list\n",
      "  PossibleDuplicates: list\n",
      "  Project: list\n",
      "  PublicationType: dict\n",
      "  Replacing: list\n",
      "  Series: list\n",
      "  Source: dict\n",
      "  Title: str\n",
      "  UpdatedBy: str\n",
      "  UpdatedDate: str\n",
      "  ValidatedBy: str\n",
      "  ValidatedDate: str\n",
      "  Year: int\n"
     ]
    }
   ],
   "source": [
    "# Get a sample document to understand structure\n",
    "sample_query = {\n",
    "    \"query\": {\"match_all\": {}},\n",
    "    \"size\": 1\n",
    "}\n",
    "\n",
    "result = es.search(index=index_name, body=sample_query)\n",
    "\n",
    "if result['hits']['hits']:\n",
    "    sample_doc = result['hits']['hits'][0]['_source']\n",
    "    print(\"Top-level fields in a publication:\")\n",
    "    for key in sorted(sample_doc.keys()):\n",
    "        value_type = type(sample_doc[key]).__name__\n",
    "        print(f\"  {key}: {value_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample publication:\n",
      "Title: RF Front-End Circuits and Architectures for IoT/LTE-A/5G Connectivity\n",
      "Year: 2018\n",
      "Has Abstract: False\n",
      "Number of authors: 5\n",
      "Number of organizations: 0\n"
     ]
    }
   ],
   "source": [
    "# Look at a specific publication's structure\n",
    "print(\"Sample publication:\")\n",
    "print(f\"Title: {sample_doc.get('Title', 'No title')}\")\n",
    "print(f\"Year: {sample_doc.get('Year', 'No year')}\")\n",
    "print(f\"Has Abstract: {'Abstract' in sample_doc and bool(sample_doc['Abstract'])}\")\n",
    "print(f\"Number of authors: {len(sample_doc.get('Persons', []))}\")\n",
    "print(f\"Number of organizations: {len(sample_doc.get('Organizations', []))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simple Text Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_text_search(query_text, size=5):\n",
    "    \"\"\"\n",
    "    Basic text search across all fields\n",
    "    \"\"\"\n",
    "    body = {\n",
    "        \"query\": {\n",
    "            \"query_string\": {\n",
    "                \"query\": query_text,\n",
    "                \"default_field\": \"*\"\n",
    "            }\n",
    "        },\n",
    "        \"size\": size,\n",
    "        \"_source\": [\"Title\", \"Year\", \"Abstract\"]\n",
    "    }\n",
    "    \n",
    "    response = es.search(index=index_name, body=body)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29329 publications about Optimized Gene-Based\n",
      "\n",
      "- Generating Optimized Trajectories for Robotic Spray Painting (2022)\n",
      "- Optimized elliptic curve cryptography and efficient elliptic curve parameter generation (2002)\n",
      "- Comments on \"A module generator for optimized CMOS buffers\" (1993)\n",
      "- Real-time generation of fully optimized holograms for optical trapping applications (2011)\n",
      "- Generalized Langevin dynamics in multiphase direct numerical simulations using hydrodynamically optimized memory kernels (2025)\n"
     ]
    }
   ],
   "source": [
    "# Test simple search\n",
    "test_query = \"Optimized Gene-Based\"\n",
    "results = simple_text_search(test_query)\n",
    "print(f\"Found {results['hits']['total']} publications about {test_query}\\n\")\n",
    "\n",
    "for hit in results['hits']['hits']:\n",
    "    doc = hit['_source']\n",
    "    print(f\"- {doc.get('Title', 'No title')} ({doc.get('Year', 'N/A')})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Field-Specific Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_by_title(title_text, size=5):\n",
    "    \"\"\"\n",
    "    Search specifically in title field\n",
    "    \"\"\"\n",
    "    body = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"Title\": {\n",
    "                    \"query\": title_text,\n",
    "                    \"operator\": \"and\"  # All words must match\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"size\": size,\n",
    "        \"_source\": [\"Title\", \"Year\", \"Abstract\"]\n",
    "    }\n",
    "    \n",
    "    return es.search(index=index_name, body=body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 publications with Optimizing Gene-Based in title\n",
      "\n",
      "- Optimizing Gene-Based Testing for Antibiotic Resistance Prediction\n",
      "  Year: 2025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test title search\n",
    "test_query = \"Optimizing Gene-Based\"\n",
    "results = search_by_title(test_query)\n",
    "print(f\"Found {results['hits']['total']} publications with {test_query} in title\\n\")\n",
    "\n",
    "for hit in results['hits']['hits'][:3]:\n",
    "    doc = hit['_source']\n",
    "    print(f\"- {doc.get('Title', 'No title')}\")\n",
    "    print(f\"  Year: {doc.get('Year', 'N/A')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Understanding Author Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author structure example:\n",
      "{\n",
      "  \"PersonData\": {\n",
      "    \"Id\": \"1b807d61-badc-457d-a7e2-f71b45042e73\",\n",
      "    \"FirstName\": \"Yan\",\n",
      "    \"LastName\": \"Li\",\n",
      "    \"DisplayName\": \"Yan Li\",\n",
      "    \"BirthYear\": 0,\n",
      "    \"IsDeleted\": false,\n",
      "    \"HasPublications\": true,\n",
      "    \"HasProjects\": false,\n",
      "    \"IdentifierCid\": [],\n",
      "    \"IdentifierCplPersonId\": [],\n",
      "    \"IdentifierOrcid\": [],\n",
      "    \"Identifiers\": [],\n",
      "    \"OrganizationHome\": [],\n",
      "    \"PdbCategories\": []\n",
      "  },\n",
      "  \"Organizations\": [\n",
      "    {\n",
      "      \"OrganizationData\": {\n",
      "        \"Id\": \"a400fdb2-1614-41ad-92...\n"
     ]
    }
   ],
   "source": [
    "# First, let's see how authors are structured\n",
    "if 'Persons' in sample_doc and sample_doc['Persons']:\n",
    "    print(\"Author structure example:\")\n",
    "    first_person = sample_doc['Persons'][0]\n",
    "    print(json.dumps(first_person, indent=2)[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persons field is nested: False\n"
     ]
    }
   ],
   "source": [
    "# Check if Persons is a nested field\n",
    "mapping = es.indices.get_mapping(index=index_name)\n",
    "persons_mapping = mapping[index_name]['mappings']['publication']['properties'].get('Persons', {})\n",
    "is_nested = persons_mapping.get('type') == 'nested'\n",
    "print(f\"Persons field is nested: {is_nested}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_by_author(author_name, size=5):\n",
    "    \"\"\"\n",
    "    Search by author name - handles both nested and non-nested cases\n",
    "    \"\"\"\n",
    "    # For Elasticsearch 6.x, let's use a simple approach\n",
    "    body = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"Persons.PersonData.DisplayName\": author_name\n",
    "            }\n",
    "        },\n",
    "        \"size\": size,\n",
    "        \"_source\": [\"Title\", \"Year\", \"Persons.PersonData.DisplayName\"]\n",
    "    }\n",
    "    \n",
    "    return es.search(index=index_name, body=body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7041 publications\n",
      "\n",
      "- The Subjective Judgement of Weld Quality and its Effect on Production Cost (2013)\n",
      "  Authors: Anna Öberg, Erik Åstrand...\n",
      "\n",
      "- Improved productivity by reduced variation in gas metal arc welding (GMAW) (2017)\n",
      "  Authors: Anna Öberg, Erik Åstrand...\n",
      "\n",
      "- The Construction Industry as a Loosely Coupled System - Implications for productivity and innovativity (2001)\n",
      "  Authors: Anna Dubois, Lars-Erik Gadde...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test author search\n",
    "author_results = search_by_author(\"Erik Anna\")\n",
    "print(f\"Found {author_results['hits']['total']} publications\\n\")\n",
    "\n",
    "for hit in author_results['hits']['hits'][:3]:\n",
    "    doc = hit['_source']\n",
    "    print(f\"- {doc.get('Title', 'No title')} ({doc.get('Year', 'N/A')})\")\n",
    "    \n",
    "    # Extract author names\n",
    "    if 'Persons' in doc:\n",
    "        authors = [p.get('PersonData', {}).get('DisplayName', 'Unknown') \n",
    "                  for p in doc['Persons'] if 'PersonData' in p]\n",
    "        print(f\"  Authors: {', '.join(authors[:3])}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Filtered Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_with_filters(text_query=None, year=None, year_range=None, size=10):\n",
    "    \"\"\"\n",
    "    Search with various filters\n",
    "    \"\"\"\n",
    "    must_clauses = []\n",
    "    \n",
    "    # Add text query if provided\n",
    "    if text_query:\n",
    "        must_clauses.append({\n",
    "            \"multi_match\": {\n",
    "                \"query\": text_query,\n",
    "                \"fields\": [\"Title^2\", \"Abstract\", \"Keywords.Value\"]\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    # Add year filter\n",
    "    if year:\n",
    "        must_clauses.append({\"term\": {\"Year\": year}})\n",
    "    elif year_range:\n",
    "        must_clauses.append({\"range\": {\"Year\": year_range}})\n",
    "    \n",
    "    # Build query\n",
    "    if must_clauses:\n",
    "        query = {\"bool\": {\"must\": must_clauses}}\n",
    "    else:\n",
    "        query = {\"match_all\": {}}\n",
    "    \n",
    "    body = {\n",
    "        \"query\": query,\n",
    "        \"size\": size,\n",
    "        \"sort\": [{\"Year\": {\"order\": \"desc\"}}, \"_score\"],\n",
    "        \"_source\": [\"Title\", \"Year\", \"Abstract\"]\n",
    "    }\n",
    "    \n",
    "    return es.search(index=index_name, body=body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 62 AI publications from 2023 onwards\n",
      "\n",
      "- 2025: Preface: The 6th International Workshop on Requirements Engineering for Artificial Intelligence (RE4AI’25)\n",
      "- 2025: O-RAN Intelligence Orchestration Framework for Quality-Driven Xapp Deployment and Sharing\n",
      "- 2025: One test to predict them all: Rheological characterization of complex fluids via artificial neural network\n",
      "- 2025: Nearly quantum-limited microwave amplification via interfering degenerate stimulated emission in a single artificial atom\n",
      "- 2025: Design and in vitro anticancer assessment of a click chemistry-derived dinuclear copper artificial metallo-nuclease\n"
     ]
    }
   ],
   "source": [
    "# Test filtered search - recent AI papers\n",
    "recent_ai = search_with_filters(\n",
    "    text_query=\"artificial intelligence\",\n",
    "    year_range={\"gte\": 2025}\n",
    ")\n",
    "\n",
    "print(f\"Found {recent_ai['hits']['total']} AI publications from 2023 onwards\\n\")\n",
    "\n",
    "for hit in recent_ai['hits']['hits'][:5]:\n",
    "    doc = hit['_source']\n",
    "    print(f\"- {doc.get('Year')}: {doc.get('Title', 'No title')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_publication_stats():\n",
    "    \"\"\"\n",
    "    Get aggregated statistics\n",
    "    \"\"\"\n",
    "    body = {\n",
    "        \"size\": 0,  # Don't return documents\n",
    "        \"aggs\": {\n",
    "            \"by_year\": {\n",
    "                \"terms\": {\n",
    "                    \"field\": \"Year\",\n",
    "                    \"size\": 10,\n",
    "                    \"order\": {\"_key\": \"desc\"}\n",
    "                }\n",
    "            },\n",
    "            \"by_type\": {\n",
    "                \"terms\": {\n",
    "                    \"field\": \"PublicationType.NameEng.keyword\",\n",
    "                    \"size\": 10\n",
    "                }\n",
    "            },\n",
    "            \"has_abstract\": {\n",
    "                \"filter\": {\n",
    "                    \"exists\": {\"field\": \"Abstract\"}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return es.search(index=index_name, body=body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publications by year (recent):\n",
      "  2025: 1,625 publications\n",
      "  2024: 3,962 publications\n",
      "  2023: 3,937 publications\n",
      "  2022: 3,852 publications\n",
      "  2021: 4,063 publications\n",
      "\n",
      "Top publication types:\n",
      "  Journal article: 42,519\n",
      "  Paper in proceeding: 23,473\n",
      "  Doctoral thesis: 5,219\n",
      "  Other conference contribution: 4,913\n",
      "  Licentiate thesis: 4,647\n",
      "\n",
      "Publications with abstracts: 73,607 / 95,697 (76.9%)\n"
     ]
    }
   ],
   "source": [
    "# Get and display statistics\n",
    "stats = get_publication_stats()\n",
    "\n",
    "print(\"Publications by year (recent):\")\n",
    "for bucket in stats['aggregations']['by_year']['buckets'][:5]:\n",
    "    print(f\"  {bucket['key']}: {bucket['doc_count']:,} publications\")\n",
    "\n",
    "print(\"\\nTop publication types:\")\n",
    "for bucket in stats['aggregations']['by_type']['buckets'][:5]:\n",
    "    print(f\"  {bucket['key']}: {bucket['doc_count']:,}\")\n",
    "\n",
    "total_docs = stats['hits']['total']\n",
    "with_abstract = stats['aggregations']['has_abstract']['doc_count']\n",
    "print(f\"\\nPublications with abstracts: {with_abstract:,} / {total_docs:,} ({with_abstract/total_docs*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Combined Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_publications(query=None, filters=None, size=10, from_=0, fields=None):\n",
    "    \"\"\"\n",
    "    Main search function combining all features\n",
    "    \n",
    "    Args:\n",
    "        query: Free text search\n",
    "        filters: Dict with filters like {\"year\": 2023, \"author\": \"Name\"}\n",
    "        size: Number of results\n",
    "        from_: Offset for pagination\n",
    "        fields: List of fields to return\n",
    "    \"\"\"\n",
    "    must_clauses = []\n",
    "    \n",
    "    # Text search\n",
    "    if query:\n",
    "        must_clauses.append({\n",
    "            \"multi_match\": {\n",
    "                \"query\": query,\n",
    "                \"fields\": [\"Title^3\", \"Abstract^2\", \"Keywords.Value\"],\n",
    "                \"type\": \"best_fields\"\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    # Process filters\n",
    "    if filters:\n",
    "        for key, value in filters.items():\n",
    "            if key == \"year\":\n",
    "                must_clauses.append({\"term\": {\"Year\": value}})\n",
    "            elif key == \"year_range\":\n",
    "                must_clauses.append({\"range\": {\"Year\": value}})\n",
    "            elif key == \"author\":\n",
    "                must_clauses.append({\n",
    "                    \"match\": {\"Persons.PersonData.DisplayName\": value}\n",
    "                })\n",
    "            elif key == \"type\":\n",
    "                must_clauses.append({\n",
    "                    \"term\": {\"PublicationType.Id\": value}\n",
    "                })\n",
    "    \n",
    "    # Build query\n",
    "    if must_clauses:\n",
    "        es_query = {\"bool\": {\"must\": must_clauses}}\n",
    "    else:\n",
    "        es_query = {\"match_all\": {}}\n",
    "    \n",
    "    # Build request body\n",
    "    body = {\n",
    "        \"query\": es_query,\n",
    "        \"size\": size,\n",
    "        \"from\": from_,\n",
    "        \"sort\": [{\"Year\": {\"order\": \"desc\"}}, \"_score\"]\n",
    "    }\n",
    "    \n",
    "    # Add field selection\n",
    "    if fields:\n",
    "        body[\"_source\"] = fields\n",
    "    \n",
    "    response = es.search(index=index_name, body=body)\n",
    "    \n",
    "    # Return formatted results\n",
    "    return {\n",
    "        \"total\": response[\"hits\"][\"total\"],\n",
    "        \"hits\": response[\"hits\"][\"hits\"],\n",
    "        \"query_used\": body  # For debugging\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 272 publications\n",
      "\n",
      "Query used:\n",
      "{\n",
      "  \"query\": {\n",
      "    \"bool\": {\n",
      "      \"must\": [\n",
      "        {\n",
      "          \"multi_match\": {\n",
      "            \"query\": \"microwave\",\n",
      "            \"fields\": [\n",
      "              \"Title^3\",\n",
      "              \"Abstract^2\",\n",
      "              \"Keywords.Value\"\n",
      "            ],\n",
      "            \"type\": \"best_fields\"\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"range\": {\n",
      "            \"Year\": {\n",
      "              \"gte\": 2020,\n",
      "              \"lte\": 2024\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"size\": 5,\n",
      "  \"from\": 20,\n",
      "  \"sort\": [\n",
      "    {\n",
      "      \"Year\": {\n",
      "        \"order\": \"desc\"\n",
      "      }\n",
      "    },\n",
      "    \"_score\"\n",
      "  ],\n",
      "  \"_source\": [\n",
      "    \"Title\",\n",
      "    \"Year\",\n",
      "    \"Abstract\",\n",
      "    \"Persons.PersonData.DisplayName\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "Results:\n",
      "\n",
      "- Analysis of a plasma reactor performance for direct nitrogen fixation by use of three-dimensional simulations and experiments\n",
      "  Year: 2024\n",
      "  Abstract: This study utilizes state-of-the-art in-situ measurements and advanced three-dimensional simulations...\n",
      "\n",
      "- Intermodulation spectroscopy and the nonlinear response of two-level systems in superconducting coplanar-waveguide resonators\n",
      "  Year: 2024\n",
      "  Abstract: Two-level system (TLS) loss typically limits the coherence of superconducting quantum circuits. The ...\n",
      "\n",
      "- Direct laser-written optomechanical membranes in fiber Fabry-Perot cavities\n",
      "  Year: 2024\n",
      "  Abstract: Integrated micro- and nanophotonic optomechanical experiments enable the manipulation of mechanical ...\n",
      "\n",
      "- A Compact and Wideband MMIC to Ridge Gap Waveguide Contactless Transition for Phased Array Antenna Front-Ends\n",
      "  Year: 2024\n",
      "  Abstract: A concept of a contactless in-line transition between a monolithic microwave integrated circuit (MMI...\n",
      "\n",
      "- Alkaline water electrolysis performance of mixed cation metal phosphorous trichalcogenides\n",
      "  Year: 2024\n",
      "  Abstract: A variety of mixed-cation metal phosphorus trichalcogenides (MnNiP2S6, FeCoP2S6, FeNiP2S6, CoNiP2S6,...\n"
     ]
    }
   ],
   "source": [
    "# Test the combined function\n",
    "results = search_publications(\n",
    "    query=\"microwave\",\n",
    "    filters={\n",
    "        \"year_range\": {\"gte\": 2020, \"lte\": 2024},\n",
    "    },\n",
    "    size=5,\n",
    "    fields=[\"Title\", \"Year\", \"Abstract\", \"Persons.PersonData.DisplayName\"],\n",
    "    from_=20\n",
    ")\n",
    "\n",
    "print(f\"Found {results['total']} publications\\n\")\n",
    "print(\"Query used:\")\n",
    "print(json.dumps(results['query_used'], indent=2))\n",
    "print(\"\\nResults:\")\n",
    "\n",
    "for hit in results['hits']:\n",
    "    doc = hit['_source']\n",
    "    print(f\"\\n- {doc.get('Title', 'No title')}\")\n",
    "    print(f\"  Year: {doc.get('Year', 'N/A')}\")\n",
    "    if 'Abstract' in doc:\n",
    "        print(f\"  Abstract: {doc['Abstract'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Testing and Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: Simple text search\n",
      "  Found: 156 results\n",
      "  First result: Adaptation of Escherichia coli to ciprofloxacin and enrofloxacin: Differential proteomics of the SOS response and RecA-independent mechanisms\n",
      "\n",
      "Test: Year filter only\n",
      "  Found: 3962 results\n",
      "  First result: Digitalisation and technological Innovations Towards Energy-Efficient Quarries\n",
      "\n",
      "Test: Author search\n",
      "  Found: 4689 results\n",
      "  First result: Geometric Numerical Methods: From Random Fields to Shape Matching\n",
      "\n",
      "Test: Combined search\n",
      "  Found: 371 results\n",
      "  First result: Flip-chip Integrated Superconducting Quantum Processors\n"
     ]
    }
   ],
   "source": [
    "# Test various query patterns\n",
    "test_queries = [\n",
    "    {\"description\": \"Simple text search\", \"params\": {\"query\": \"Antibiotics\"}},\n",
    "    {\"description\": \"Year filter only\", \"params\": {\"filters\": {\"year\": 2024}}},\n",
    "    {\"description\": \"Author search\", \"params\": {\"filters\": {\"author\": \"Erik\"}}},\n",
    "    {\"description\": \"Combined search\", \"params\": {\n",
    "        \"query\": \"quantum\",\n",
    "        \"filters\": {\"year_range\": {\"gte\": 2023}}\n",
    "    }}\n",
    "]\n",
    "\n",
    "for test in test_queries:\n",
    "    print(f\"\\nTest: {test['description']}\")\n",
    "    try:\n",
    "        results = search_publications(**test['params'], size=2)\n",
    "        print(f\"  Found: {results['total']} results\")\n",
    "        if results['hits']:\n",
    "            print(f\"  First result: {results['hits'][0]['_source'].get('Title', 'No title')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Next Steps\n",
    "\n",
    "Now that we have working search functions, we can:\n",
    "1. Add more sophisticated filters\n",
    "2. Implement scroll API for large result sets\n",
    "3. Create specialized functions for common queries\n",
    "4. Build an agent that uses these tools\n",
    "\n",
    "What would you like to explore next?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_by_phrase(phrase, field=\"Title\", size=5):\n",
    "    \"\"\"\n",
    "    Search for exact phrase within a specific field\n",
    "    The phrase must appear exactly as given, but can be part of a larger text\n",
    "    \n",
    "    Args:\n",
    "        phrase: Exact phrase to search for\n",
    "        field: Field to search in (default: Title)\n",
    "        size: Number of results to return\n",
    "    \"\"\"\n",
    "    body = {\n",
    "        \"query\": {\n",
    "            \"match_phrase\": {\n",
    "                field: phrase\n",
    "            }\n",
    "        },\n",
    "        \"size\": size,\n",
    "        \"_source\": [\"Title\", \"Year\", \"Abstract\"],\n",
    "        \"highlight\": {\n",
    "            \"fields\": {\n",
    "                field: {}  # This will show where the phrase was found\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return es.search(index=index_name, body=body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPARING SEARCH FUNCTIONS ===\n",
      "Test phrase: 'Optimizing Gene-Based'\n",
      "\n",
      "1. simple_text_search (query_string across all fields):\n",
      "   Found: 28938 results\n",
      "   - Optimizing Gene-Based Testing for Antibiotic Resistance Prediction...\n",
      "   - Dampening variations in wind power generation-the effect of optimizing geographi...\n",
      "   - Optimizing robot trajectories for automatic robot code generation...\n",
      "\n",
      "2. search_by_title (match with AND operator):\n",
      "   Found: 1 results\n",
      "   - Optimizing Gene-Based Testing for Antibiotic Resistance Prediction...\n",
      "\n",
      "3. search_by_phrase (NEW - match_phrase):\n",
      "   Found: 1 results\n",
      "   - Optimizing Gene-Based Testing for Antibiotic Resistance Prediction...\n",
      "     Highlighted: <em>Optimizing</em> <em>Gene</em>-<em>Based</em> Testing for Antibiotic Resistance Prediction\n",
      "\n",
      "4. search_with_filters (multi_match with field boosting):\n",
      "   Found: 28309 results\n",
      "   - Optimizing Gene-Based Testing for Antibiotic Resistance Prediction...\n",
      "   - Optimizing hydration and performance of phosphogypsum based cementitious system ...\n",
      "   - Optimizing a link-based travel incentive scheme integrating personal carbon trad...\n",
      "\n",
      "5. search_publications (final combined function):\n",
      "   Found: 28309 results\n",
      "   - Optimizing Gene-Based Testing for Antibiotic Resistance Prediction...\n",
      "   - Optimizing hydration and performance of phosphogypsum based cementitious system ...\n",
      "   - Optimizing a link-based travel incentive scheme integrating personal carbon trad...\n",
      "\n",
      "\n",
      "=== AUTHOR SEARCH COMPARISON ===\n",
      "Test author: 'Fager'\n",
      "\n",
      "1. search_by_author function:\n",
      "   Found: 304 results\n",
      "\n",
      "2. search_publications with author filter:\n",
      "   Found: 304 results\n"
     ]
    }
   ],
   "source": [
    "# Test all our search functions with the same query to compare results\n",
    "test_phrase = \"Optimizing Gene-Based\"\n",
    "\n",
    "print(\"=== COMPARING SEARCH FUNCTIONS ===\")\n",
    "print(f\"Test phrase: '{test_phrase}'\\n\")\n",
    "\n",
    "# 1. Simple text search (from cell 3)\n",
    "print(\"1. simple_text_search (query_string across all fields):\")\n",
    "try:\n",
    "    results = simple_text_search(test_phrase, size=3)\n",
    "    print(f\"   Found: {results['hits']['total']} results\")\n",
    "    for hit in results['hits']['hits']:\n",
    "        print(f\"   - {hit['_source'].get('Title', 'No title')[:80]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {str(e)}\")\n",
    "\n",
    "print(\"\\n2. search_by_title (match with AND operator):\")\n",
    "try:\n",
    "    results = search_by_title(test_phrase, size=3)\n",
    "    print(f\"   Found: {results['hits']['total']} results\")\n",
    "    for hit in results['hits']['hits']:\n",
    "        print(f\"   - {hit['_source'].get('Title', 'No title')[:80]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {str(e)}\")\n",
    "\n",
    "print(\"\\n3. search_by_phrase (NEW - match_phrase):\")\n",
    "try:\n",
    "    results = search_by_phrase(test_phrase, field=\"Title\", size=3)\n",
    "    print(f\"   Found: {results['hits']['total']} results\")\n",
    "    for hit in results['hits']['hits']:\n",
    "        print(f\"   - {hit['_source'].get('Title', 'No title')[:80]}...\")\n",
    "        if 'highlight' in hit:\n",
    "            print(f\"     Highlighted: {hit['highlight']['Title'][0]}\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {str(e)}\")\n",
    "\n",
    "print(\"\\n4. search_with_filters (multi_match with field boosting):\")\n",
    "try:\n",
    "    results = search_with_filters(text_query=test_phrase, size=3)\n",
    "    print(f\"   Found: {results['hits']['total']} results\")\n",
    "    for hit in results['hits']['hits']:\n",
    "        print(f\"   - {hit['_source'].get('Title', 'No title')[:80]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {str(e)}\")\n",
    "\n",
    "print(\"\\n5. search_publications (final combined function):\")\n",
    "try:\n",
    "    results = search_publications(query=test_phrase, size=3)\n",
    "    print(f\"   Found: {results['total']} results\")\n",
    "    for hit in results['hits']:\n",
    "        print(f\"   - {hit['_source'].get('Title', 'No title')[:80]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {str(e)}\")\n",
    "\n",
    "# Bonus: Let's also test author search\n",
    "print(\"\\n\\n=== AUTHOR SEARCH COMPARISON ===\")\n",
    "test_author = \"Fager\"\n",
    "print(f\"Test author: '{test_author}'\\n\")\n",
    "\n",
    "print(\"1. search_by_author function:\")\n",
    "try:\n",
    "    results = search_by_author(test_author, size=3)\n",
    "    print(f\"   Found: {results['hits']['total']} results\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {str(e)}\")\n",
    "\n",
    "print(\"\\n2. search_publications with author filter:\")\n",
    "try:\n",
    "    results = search_publications(filters={\"author\": test_author}, size=3)\n",
    "    print(f\"   Found: {results['total']} results\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
